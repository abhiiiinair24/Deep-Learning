{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELDMxiI_HtYA"
      },
      "source": [
        "# Part II: Investigating the Vanishing Gradient Problem [20 pts]\n",
        "Experimentally demonstrate the vanishing gradient problem in deep CNNs and understand how ResNet's architecture mitigates it. You will also explore other key CNN concepts through additional experiments."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwR9EkwsJvy8",
        "outputId": "33629df5-44ba-4e6f-b69a-af9a25b8abad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!cp \"/content/gdrive/MyDrive/A1_Dataset/cnn_dataset.zip\" /content/\n",
        "#!unzip -q /content/cnn_dataset.zip -d /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a2CID63J3ZL",
        "outputId": "a2780bf8-93f2-4af7-b32f-e36c2a87371c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/cnn_dataset.zip, /content/cnn_dataset.zip.zip or /content/cnn_dataset.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUPQo15pKF9t",
        "outputId": "6b4330b3-ee9a-444a-f501-c389c98045c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gdrive\tsample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!mkdir -p /content/cnn_dataset\n",
        "#!mv /content/dogs /content/cnn_dataset/\n",
        "#!mv /content/food /content/cnn_dataset/\n",
        "#!mv /content/vehicles /content/cnn_dataset/"
      ],
      "metadata": {
        "id": "T_OuqG8409o5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "from collections import Counter\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "dataPath = '/content/gdrive/MyDrive/Colab Notebooks/CSE 676 A1 Shivam Abhishek/cnn_dataset'\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64,64)),\n",
        "    transforms.ToTensor(), #Normalised pixel values to [0-1] from [0-255], RGB\n",
        "    #Also normalising now since VGG works better with mean/std\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
        "])\n",
        "#dataset = ImageFolder(\"/content/cnn_dataset\", transform=transform)\n",
        "dataset = ImageFolder(dataPath, transform=transform)\n",
        "\n",
        "print(\"Total images:\", len(dataset))\n",
        "print(\"Classes:\", dataset.classes)\n",
        "print(Counter(dataset.targets))"
      ],
      "metadata": {
        "id": "_vqFnixYKHTa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "70f755b5-88e2-43e6-b560-d2980803f8c8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2016490094.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m ])\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#dataset = ImageFolder(\"/content/cnn_dataset\", transform=transform)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total images:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mallow_empty\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     ):\n\u001b[0;32m--> 328\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         samples = self.make_dataset(\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;31m# is potentially overridden and thus could have a different logic.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The class_to_idx parameter cannot be None.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         return make_dataset(\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_valid_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_empty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfnames\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollowlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/os.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #Based on here https://www.kaggle.com/code/subhajeetdas/1-pytorch-cuda-check\n",
        "print(len(dataset.classes))\n",
        "print(device)\n"
      ],
      "metadata": {
        "id": "EVsUudKIdIai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "dataset_size = len(dataset)\n",
        "train_size = int(0.70 * dataset_size)\n",
        "val_size = int(0.15 * dataset_size)\n",
        "test_size = dataset_size - train_size - val_size  # To ensure it sums exactly\n",
        "\n",
        "train_set, val_set, test_set = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_set,batch_size=32,shuffle=True)\n",
        "val_loader   = DataLoader(val_set,batch_size=32,shuffle=False)\n",
        "test_loader  = DataLoader(test_set,batch_size=32,shuffle=False)"
      ],
      "metadata": {
        "id": "tF46E59edJUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHtKDVJQdNSl",
        "outputId": "09178a24-9e51-4d01-d106-9e22024e4dd3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x6bdnAxEdUMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28F6FYxYHtYD"
      },
      "source": [
        "## Step 1: Create a deeper version of your VGG-16 network (VGG-Deep)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "qePacUwelA5y"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_RtFjU2HtYE"
      },
      "outputs": [],
      "source": [
        "### ADD YOUR CODE HERE ###\n",
        "#This is taken from Part 1's VGG:\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class vggDeep(nn.Module):\n",
        "    def __init__(self, numClasses):\n",
        "        super(vggDeep, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3,64,3,padding=1)\n",
        "        self.conv2 = nn.Conv2d(64,64,3,padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(2,2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64,128,3,padding=1)\n",
        "        self.conv4 = nn.Conv2d(128,128,3,padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(2,2)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(128,256,3,padding=1)\n",
        "        self.conv6 = nn.Conv2d(256,256,3,padding=1)\n",
        "        self.conv7 = nn.Conv2d(256,256,3,padding=1)\n",
        "        self.conv8  = nn.Conv2d(256,512,3,padding=1)\n",
        "        self.conv9  = nn.Conv2d(512,512,3,padding=1)\n",
        "        self.conv10 = nn.Conv2d(512,512,3,padding=1)\n",
        "        self.conv11 = nn.Conv2d(512,512,3,padding=1)\n",
        "\n",
        "        self.pool3 = nn.MaxPool2d(2,2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc1 = nn.Linear(512,512)\n",
        "        self.fc2 = nn.Linear(512,256)\n",
        "        self.fc3 = nn.Linear(256,numClasses)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.relu(self.conv1(x))\n",
        "        out = self.relu(self.conv2(out))\n",
        "        out = self.pool1(out)\n",
        "        out = self.relu(self.conv3(out))\n",
        "        out = self.relu(self.conv4(out))\n",
        "        out = self.pool2(out)\n",
        "        out = self.relu(self.conv5(out))\n",
        "        out = self.relu(self.conv6(out))\n",
        "        out = self.relu(self.conv7(out))\n",
        "       #Needed to add these 4\n",
        "        out = self.relu(self.conv8(out))\n",
        "        out = self.relu(self.conv9(out))\n",
        "        out = self.relu(self.conv10(out))\n",
        "        out = self.relu(self.conv11(out))\n",
        "\n",
        "        out = self.pool3(out)\n",
        "        out = self.avgpool(out)\n",
        "        out = torch.flatten(out,1)\n",
        "        out = self.relu(self.fc1(out))\n",
        "        out = self.relu(self.fc2(out))\n",
        "        out = self.fc3(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXDwR11fHtYF"
      },
      "source": [
        "## Step 2: Training VGG-Deep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65UsEGamHtYG"
      },
      "outputs": [],
      "source": [
        "### ADD YOUR CODE HERE ###\n",
        "import torch.optim as optim\n",
        "#Based on Abhishek's code from Part 1\n",
        "def weights_init_he(m):\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "\n",
        "model = vggDeep(numClasses=3).to(device)\n",
        "model.apply(weights_init_he)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(),lr=0.01)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer,step_size=5,gamma=0.5)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This is for the gradient tracking:\n",
        "gradient_norms = {name: [] for name,_ in model.named_modules() if isinstance(_,nn.Conv2d)}\n",
        "\n",
        "def gradient_hook(name):\n",
        "    def hook(module, grad_input, grad_output):\n",
        "        gradient_norms[name].append(grad_output[0].norm(p=2).item())\n",
        "    return hook\n",
        "\n",
        "for name, layer in model.named_modules():\n",
        "    if isinstance(layer,nn.Conv2d):\n",
        "        layer.register_full_backward_hook(gradient_hook(name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "zHYSHrEkjk63",
        "outputId": "b72c2e9b-79cf-43b9-bd08-9a809a1edb83"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_deep' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-753960962.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moptimizer_deep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_deep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mscheduler_deep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_deep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_deep' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model,epochs=15):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0\n",
        "        for x,y in train_loader:\n",
        "            x,y = x.to(device),y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            out = model(x)\n",
        "            loss = criterion(out,y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        scheduler.step()\n",
        "\n",
        "        print(\"Epoch: \", (epoch+1))\n",
        "        print(\"Loss: \", running_loss/len(train_loader))\n",
        "train_model(model)"
      ],
      "metadata": {
        "id": "vz0qzENLmuhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOZHEJp8HtYH"
      },
      "source": [
        "<span style='color:green'>### YOUR ANSWER ###</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF2MDSseHtYI"
      },
      "source": [
        "## Step 3: Gradient analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsMQTPIDHtYI"
      },
      "source": [
        "- Track the average L2 norm of the gradients in each convolutional layer using PyTorch hooks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5L_ICZYHtYJ"
      },
      "outputs": [],
      "source": [
        "### ADD YOUR CODE HERE ###\n",
        "plt.figure()\n",
        "\n",
        "for name,norms in gradient_norms.items():\n",
        "    plt.plot(norms,label=name)\n",
        "\n",
        "plt.legend()\n",
        "plt.title(\"Gradient Norms\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8OufWx_HtYK"
      },
      "source": [
        "- Create a plot showing the average gradient norm for each convolutional layer over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-1CNjrmHtYK"
      },
      "outputs": [],
      "source": [
        "### ADD YOUR CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5-Gb8qLHtYK"
      },
      "source": [
        "- Create a separate plot showing the gradient norms for a subset of layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVB9z1NiHtYL"
      },
      "outputs": [],
      "source": [
        "### ADD YOUR CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eS6or7oHtYL"
      },
      "source": [
        "<span style='color:green'>### YOUR ANSWER ###</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_BSo-gJHtYL"
      },
      "source": [
        "## Step 4: Comparison with VGG-16 and ResNet-18"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0m6wHadPHtYM"
      },
      "source": [
        "- Compare the training curves (loss and accuracy vs. epoch) of VGG-Deep, VGG-16, and ResNet-18."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBJfKF8LHtYM"
      },
      "outputs": [],
      "source": [
        "### ADD YOUR CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT5TU0hyHtYM"
      },
      "source": [
        "- Discuss how ResNetâ€™s residual connections impact the gradient flow compared to VGG-Deep."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpDmdiHeHtYN"
      },
      "source": [
        "<span style='color:green'>### YOUR ANSWER ###</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYQyHak9HtYN"
      },
      "source": [
        "## Step 5: Investigate and analyze more setups"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D3Nc4QqHtYN"
      },
      "source": [
        "- Select any THREE experiments to investigate and analyze."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0Gpy2oMHtYO"
      },
      "source": [
        "### Experiment 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ng951zn-HtYO"
      },
      "outputs": [],
      "source": [
        "### ADD YOUR CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq1iGGeLHtYO"
      },
      "source": [
        "<span style='color:green'>### YOUR ANSWER ###</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gy0ubVRPHtYO"
      },
      "source": [
        "### Experiment 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOMMiA7rHtYO"
      },
      "outputs": [],
      "source": [
        "### ADD YOUR CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OtjE_OZHtYP"
      },
      "source": [
        "<span style='color:green'>### YOUR ANSWER ###</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJPf6fzHHtYP"
      },
      "source": [
        "### Experiment 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MaxKibjHtYP"
      },
      "outputs": [],
      "source": [
        "### ADD YOUR CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaRFFRywHtYP"
      },
      "source": [
        "<span style='color:green'>### YOUR ANSWER ###</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My_RPkq8HtYP"
      },
      "source": [
        "## Step 6: Analysis and discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P99zSxZ-HtYP"
      },
      "source": [
        "a. Analyze your gradient norm plots. Do they demonstrate the vanishing gradient problem? Explain how the gradient norm changes as you move deeper into VGG-Deep. Be specific and quantitative (e.g., \"The gradient norm of layer 2 is X times larger than the gradient norm of layer 10\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoffH6wYHtYQ"
      },
      "source": [
        "<span style='color:green'>### YOUR ANSWER ###</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLTsASLeHtYQ"
      },
      "source": [
        "b. Explain why the vanishing gradient problem occurs in deep networks. Relate this to the backpropagation algorithm and the chain rule. Discuss how the repeated multiplication of small gradients can lead to extremely small values in earlier layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QwPAJ0hHtYQ"
      },
      "source": [
        "<span style='color:green'>### YOUR ANSWER ###</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7Hd5mL7HtYQ"
      },
      "source": [
        "c. Explain how ResNet's architecture (residual connections) helps alleviate the vanishing gradient problem. Explain how the identity mapping allows gradients to flow more easily through the network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XX9DR-kJHtYQ"
      },
      "source": [
        "<span style='color:green'>### YOUR ANSWER ###</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mt_u8EPaHtYR"
      },
      "source": [
        "d. Discuss the theoretical impact of batch normalization on the vanishing/exploding gradient problem. Explain how it helps stabilize and accelerate training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7Nq8TpYHtYR"
      },
      "source": [
        "<span style='color:green'>### YOUR ANSWER ###</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FX5rltolHtYX"
      },
      "source": [
        "e. Summarize the key findings from your three chosen investigations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlxqBZCvHtYX"
      },
      "source": [
        "<span style='color:green'>### YOUR ANSWER ###</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKqe0-uEHtYX"
      },
      "source": [
        "f. References. Include details on all the resources used to complete this part."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_VF_8ezHtYX"
      },
      "source": [
        "<span style='color:green'>### YOUR ANSWER ###</span>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}